Intensity-Modulated Radiation Therapy (IMRT) is a method for treating cancers by aiming radiation to cancer tumor(s) while minimizing radiation to organs-at-risk from a robot's tool frame. Computationally finding the correct treatment plan for a target volume is often an exhaustive combinatorial search problem where traditional optimization methods have not yielded real-time feasible results. Aiming to automate the beam orientation and intensity modulation process, we introduce a novel set of techniques leveraging (i) pattern recognition, (ii) monte carlo evaluations, (iii) game theory, and (iv)  neuro-dynamic programming. We optimize a deep neural network policy that guides Monte Carlo simulations of promising beamlets. 
Seeking a saddle equilibrium, we let  two fictitious neural network players,  within a zero-sum markov game framework, alternatingly play a best response to their opponent's mixed strategy profile during episodes of a two-player markov decision game. During inference, the optimized policy predicts feasible beam angles on test target volumes. This work merges the beam orientation and fluence map optimization subproblems in IMRT sequential treatment planning system into one pipeline. We formally introduce our approach, and present numerical results for coplanar beam angles on prostate cases.

Dynamic programming and reinforcement learning provides an effective tool in performing difficult trajectory-following tasks in the presence of high uncertainty. For highly nonlinear, complex dynamics, local linear controllers can be used to approximate  high-dimensional robot states so as to give optimal policies for performing programming by demonstration tasks. We evaluate the guided policy search algorithm on end-to-end visuomotor training of deep policies on select tasks for high-dimensional robots tasked with performing complex tasks.

Multistage decision policies provide useful control strategies in high-dimensional state spaces, particularly in complex control tasks.  However, they exhibit weak performance guarantees in the presence of disturbance, model mismatch, or model uncertainties. This brittleness limits their use in high-risk scenarios.
We present how to quantify the sensitivity of such policies  in order to inform of their robustness capacity. We also propose  a minimax iterative dynamic game framework for designing robust policies in the presence of disturbance/uncertainties.
We test the quantification hypothesis on a carefully designed deep neural network policy; we then pose a minimax iterative dynamic game (iDG) framework for improving policy robustness in the presence of adversarial disturbances. We evaluate our iDG framework on a mecanum-wheeled robot, whose goal is to find a ocally robust optimal multistage policy that achieve a given goal-reaching task.
The algorithm is simple and adaptable for designing meta-learning/deep policies that are robust against disturbances, model mismatch, or model uncertainties, up to a disturbance bound. Videos of the results are on the author's  \href{http://ecs.utdallas.edu/~opo140030/iros18/iros2018.html}{\underline{website}}, while the codes for reproducing our experiments are on \href{https://github.com/lakehanne/youbot/tree/rilqg}{\underline{github}}. A self-contained environment for reproducing our results is on \href{https://hub.docker.com/r/lakehanne/youbotbuntu14/}{\underline{docker}}.

Deep reinforcement learning methods aim to deliver high performance control policies on systems with complex difficult-to-model dynamics and with complex multi-modal sensory input \cite{levine2016end}. However, many challenges remain, including data efficiency of the learning process and robustness of the resulting policies. Training robots in the real world can be expensive and hazardous, demanding highly data-efficient learning. This requirement can be alleviated by training in simulation, but this then demands robustness of the policy for real-world generalization.

Neural networks are known to be effective function approximators. Recently, deep neural networks have proven to be very effective in pattern recognition, classification tasks and human-level control to model highly nonlinear real-world systems. This paper investigates the effectiveness of deep neural networks in the modeling of dynamical systems with complex behavior. Three deep neural network structures are trained on sequential data, and we investigate the effectiveness of these networks in modeling associated characteristics of the underlying dynamical systems. We carry out similar evaluations on select publicly available system identification datasets. We demonstrate that deep neural networks are effective model estimators from input-output data.

Precise patient positioning is fundamental to successful removal of malignant tumors during treatment of head and neck cancers.  Errors in patient positioning have been known to damage critical organs and cause complications.   To better address issues of patient positioning and motion, we introduce a 3-DOF  neuro-adaptive soft-robot, called Soft-NeuroAdapt to correct deviations along 3 axes. The robot consists of inflatable air bladders that adaptively control head deviations from target while ensuring patient safety and comfort.  The adaptive-neuro controller combines a state feedback component, a feedforward regulator, and a neural network that ensures correct adaptation. States are measured by a 3D vision system. We validate Soft-NeuroAdapt on a 3D printed head-and-neck dummy, and demonstrate that the controller provides adaptive actuation that compensates for intrafractional deviations in patient positioning.

This work presents an on-going investigation of the control of a pneumatic soft-robot actuator addressing accurate patient positioning systems in maskless head and neck cancer radiotherapy. We employ two RGB-D sensors in a sensor fusion scheme to better estimate a patient's head pitch motion. A system identification prediction error model is used to obtain a linear time invariant state space model. We then use the model to design a linear quadratic Gaussian feedback controller to manipulate the patient head position based on sensed head pitch motion. Experiments demonstrate the success of our approach.

We present an initial examination of a novel approach toward accurately positioning a patient during head and neck intensity modulated radiotherapy (IMRT). Position-based visual-servoing of a radio-transparent soft robot is used to control the flexion/extension cranial  motion of a manikin head. A Kinect RGB-D camera is used to measure head position and the error between the sensed and desired position is used to control a pneumatic system which regulates pressure within an inflatable air bladder (IAB). Results show that the system is capable of controlling head motion to within 2mm with respect to a reference trajectory. This establishes proof-of-concept that using multiple IABs and actuators can improve cancer treatment.